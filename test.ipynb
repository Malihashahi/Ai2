{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "image = face_recognition.load_image_file(\"test.png\")\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32, 487, 94, 425), (58, 121, 94, 85), (149, 494, 211, 432)]\n"
     ]
    }
   ],
   "source": [
    "print(face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "known_image = face_recognition.load_image_file(\"biden.png\")\n",
    "unknown_image = face_recognition.load_image_file(\"biden2.jpg\")\n",
    "\n",
    "biden_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "unknown_encoding = face_recognition.face_encodings(unknown_image)[0]\n",
    "\n",
    "results = face_recognition.compare_faces([biden_encoding], unknown_encoding)\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'chin': [(435, 48), (435, 55), (435, 63), (435, 70), (436, 77), (439, 85), (441, 92), (445, 99), (452, 102), (460, 101), (468, 97), (476, 91), (483, 85), (488, 77), (491, 69), (493, 60), (494, 50)], 'left_eyebrow': [(435, 45), (437, 42), (441, 42), (445, 43), (450, 45)], 'right_eyebrow': [(457, 46), (464, 45), (470, 46), (476, 48), (481, 52)], 'nose_bridge': [(453, 51), (451, 56), (450, 61), (449, 67)], 'nose_tip': [(445, 69), (447, 71), (450, 72), (454, 71), (457, 71)], 'left_eye': [(439, 49), (441, 47), (445, 48), (448, 51), (444, 51), (441, 50)], 'right_eye': [(463, 52), (466, 50), (470, 50), (473, 53), (470, 54), (466, 53)], 'top_lip': [(443, 80), (445, 79), (448, 78), (450, 79), (453, 79), (458, 80), (464, 82), (462, 82), (453, 81), (450, 81), (448, 81), (444, 80)], 'bottom_lip': [(464, 82), (458, 84), (453, 85), (450, 85), (447, 84), (445, 83), (443, 80), (444, 80), (448, 81), (450, 82), (453, 82), (462, 82)]}, {'chin': [(96, 69), (95, 73), (95, 77), (96, 80), (96, 84), (98, 88), (99, 92), (101, 95), (104, 96), (108, 96), (113, 93), (117, 91), (120, 87), (123, 83), (124, 79), (125, 74), (126, 70)], 'left_eyebrow': [(96, 67), (97, 66), (99, 65), (101, 66), (103, 67)], 'right_eyebrow': [(107, 67), (110, 67), (113, 67), (116, 68), (118, 70)], 'nose_bridge': [(105, 70), (104, 73), (103, 75), (102, 78)], 'nose_tip': [(101, 79), (102, 80), (103, 81), (105, 80), (107, 80)], 'left_eye': [(97, 69), (99, 68), (100, 68), (102, 70), (100, 70), (98, 70)], 'right_eye': [(110, 70), (111, 69), (113, 69), (115, 71), (113, 71), (111, 71)], 'top_lip': [(99, 85), (100, 84), (102, 84), (103, 84), (105, 84), (108, 85), (110, 86), (109, 86), (105, 85), (103, 85), (102, 85), (100, 85)], 'bottom_lip': [(110, 86), (107, 88), (105, 88), (103, 88), (102, 88), (100, 87), (99, 85), (100, 85), (102, 86), (103, 86), (105, 86), (109, 86)]}, {'chin': [(433, 167), (433, 175), (434, 182), (436, 190), (439, 197), (444, 203), (450, 208), (457, 212), (463, 212), (470, 211), (475, 206), (481, 201), (486, 195), (489, 187), (490, 179), (491, 171), (491, 162)], 'left_eyebrow': [(437, 166), (440, 162), (445, 161), (450, 161), (455, 162)], 'right_eyebrow': [(466, 162), (470, 160), (475, 159), (481, 159), (484, 162)], 'nose_bridge': [(461, 167), (461, 172), (461, 177), (462, 182)], 'nose_tip': [(457, 185), (459, 186), (462, 186), (465, 185), (468, 184)], 'left_eye': [(444, 168), (447, 166), (450, 166), (454, 168), (450, 170), (446, 170)], 'right_eye': [(469, 167), (471, 164), (475, 163), (478, 165), (475, 167), (472, 168)], 'top_lip': [(453, 194), (456, 193), (460, 192), (463, 192), (465, 191), (468, 192), (472, 193), (470, 193), (465, 193), (463, 193), (460, 193), (455, 194)], 'bottom_lip': [(472, 193), (469, 195), (466, 197), (463, 197), (460, 197), (457, 197), (453, 194), (455, 194), (460, 195), (463, 195), (465, 194), (470, 193)]}]\n"
     ]
    }
   ],
   "source": [
    "print(face_landmarks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# This is a demo of running face recognition on live video from your webcam. It's a little more complicated than the\n",
    "# other example, but it includes some basic performance tweaks to make things run a lot faster:\n",
    "#   1. Process each video frame at 1/4 resolution (though still display it at full resolution)\n",
    "#   2. Only detect faces in every other frame of video.\n",
    "\n",
    "# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(1)\n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "obama_image = face_recognition.load_image_file(\"majid.jpg\")\n",
    "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "\n",
    "# Load a second sample picture and learn how to recognize it.\n",
    "biden_image = face_recognition.load_image_file(\"biden.png\")\n",
    "biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    obama_face_encoding,\n",
    "    biden_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Majid\",\n",
    "    \"Joe Biden\"\n",
    "]\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        \n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # # If a match was found in known_face_encodings, just use the first one.\n",
    "            # if True in matches:\n",
    "            #     first_match_index = matches.index(True)\n",
    "            #     name = known_face_names[first_match_index]\n",
    "\n",
    "            # Or instead, use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index] \n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
